{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cda7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import pandas as pd\n",
    "from consumption_model_ch.utils import get_habe_filepath\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_consumption_all_hh(\n",
    "        co_name,\n",
    "        dir_habe=None,\n",
    "        option='disaggregated',\n",
    "        write_dir=\"write_files\",\n",
    "):\n",
    "    # 1. Get some metadata from the consumption database\n",
    "    co = bd.Database(co_name)\n",
    "    year_habe = co.metadata['year_habe']\n",
    "    dir_habe = dir_habe or co.metadata['dir_habe']\n",
    "\n",
    "    # 2. Extract total demand from HABE\n",
    "    path_beschrei = get_habe_filepath(dir_habe, year_habe, 'Datenbeschreibung')\n",
    "    path_ausgaben = get_habe_filepath(dir_habe, year_habe, 'Ausgaben')\n",
    "    path_mengen = get_habe_filepath(dir_habe, year_habe, 'Mengen')\n",
    "\n",
    "    # change codes to be consistent with consumption database and Andi's codes\n",
    "    co = bd.Database(co_name)\n",
    "    ausgaben = pd.read_csv(path_ausgaben, sep='\\t')\n",
    "    mengen = pd.read_csv(path_mengen, sep='\\t')\n",
    "    ausgaben.columns = [col.lower() for col in ausgaben.columns]\n",
    "    mengen.columns = [col.lower() for col in mengen.columns]\n",
    "    codes_co_db = sorted([act['code'] for act in co])\n",
    "    columns_a = ausgaben.columns.values\n",
    "    columns_m = [columns_a[0]]\n",
    "    for code_a in columns_a[1:]:\n",
    "        code_m = code_a.replace('a', 'm')\n",
    "        if code_m in codes_co_db:\n",
    "            columns_m.append(code_m)\n",
    "        else:\n",
    "            columns_m.append(code_a)\n",
    "    ausgaben.columns = columns_m\n",
    "\n",
    "    # Compute total consumption\n",
    "    total_consumption = ausgaben.sum()\n",
    "    total_consumption = total_consumption.drop('haushaltid')\n",
    "    mengen = mengen.sum()\n",
    "    mengen = mengen.drop('haushaltid')\n",
    "    for i in range(len(mengen)):\n",
    "        try:\n",
    "            total_consumption[mengen.index[i]] = mengen.values[i]\n",
    "        except KeyError:\n",
    "            print(mengen.index[i])\n",
    "\n",
    "    # Add other useful info, eg number of households and number of people\n",
    "    meta = pd.read_excel(path_beschrei, sheet_name='Tabellen', skiprows=8, usecols=[0, 1, 3, 4])\n",
    "    meta.columns = ['category1', 'category2', 'n_rows', 'n_cols']\n",
    "    meta.dropna(subset=['n_rows'], inplace=True)\n",
    "\n",
    "    # Combine some columns together\n",
    "    temp1 = meta[meta['category1'].notnull()][['category1', 'n_rows', 'n_cols']]\n",
    "    temp1.columns = ['category2', 'n_rows', 'n_cols']\n",
    "    temp2 = meta[meta['category2'].notnull()][['category2', 'n_rows', 'n_cols']]\n",
    "    meta = pd.concat([temp1, temp2])\n",
    "    meta.set_index('category2', inplace=True)\n",
    "\n",
    "    # Add info\n",
    "    total_consumption['n_households'] = meta.loc['HABE{}_Ausgaben'.format(year_habe)]['n_rows']\n",
    "    total_consumption['n_people'] = meta.loc['HABE{}_Personen'.format(year_habe)]['n_rows']\n",
    "\n",
    "    # Save total demand\n",
    "    write_dir = Path(write_dir)\n",
    "    path_demand = write_dir / \"habe_totaldemands.xlsx\"\n",
    "    total_consumption.to_excel(path_demand)\n",
    "\n",
    "    # 3. Options\n",
    "\n",
    "    # OPTION 1 aggregated. Total demands extract directly from HABE raw files\n",
    "    # Excel file `habe_totaldemands.xlsx` contains sums of all private households in Switzerland for all categories of\n",
    "    # the HBS. Units are the same as in the HBS (please refer to the SI-excel of Andi's ES&T-paper in order to translate\n",
    "    # the codenames). The attached vector is in \"per month\" quantities.\n",
    "\n",
    "    # OPTION 2 disaggregated. Andi's total demands from his Swiss consumption model\n",
    "    # Excel file `heia2_totaldemands.xlsx` contains sums of all private households in Switzerland for all categories of\n",
    "    # the HBS. Please note that the units are basically the same as in the HBS (please refer to the SI-excel of Andi's\n",
    "    # ES&T-paper in order to translate the codenames). However, the attached vector is in \"per year\" instead of in\n",
    "    # \"per month\". Furthermore, there are a couple of demands that were computed by the model itself. The codenames for\n",
    "    # these computed/imputed categories start with \"mx\" and the units are as follows:\n",
    "    # - kWh per year for electricity\n",
    "    # - MJ per year for heating\n",
    "    # - cubic meters per year for water supply and wastewater collection\n",
    "    # - number of waste bags per year for refuse collection\n",
    "\n",
    "    if option == 'aggregated':\n",
    "        df = pd.read_excel(path_demand)\n",
    "        df.columns = ['code', 'amount']\n",
    "        df.set_index('code', inplace=True)\n",
    "        n_households = int(df.loc['n_households', 'amount'])\n",
    "        # n_people     = int(df.loc['n_people', 'amount'])\n",
    "        df = df.drop(['n_households', 'n_people'])\n",
    "        df = df.reset_index()\n",
    "\n",
    "    elif option == 'disaggregated':\n",
    "        path = dirpath / \"functional_units\" / 'habe20092011_hh_prepared_imputed.csv'\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        n_households = df.shape[0]\n",
    "        df = df.drop('haushaltid', axis=1).sum()\n",
    "        df = df.reset_index()\n",
    "        df.columns = ['code', 'amount']\n",
    "\n",
    "    else:\n",
    "        n_households = None\n",
    "\n",
    "    # 4. Add total inputs from Andi's model as swiss consumption activity\n",
    "    co_act_name = 'ch hh all consumption {}'.format(option)\n",
    "    try:\n",
    "        co.get(co_act_name).delete()\n",
    "    except:\n",
    "        pass\n",
    "    consumption_all = co.new_activity(co_act_name, name=co_act_name, location='CH', unit='1 month of consumption')\n",
    "    consumption_all.save()\n",
    "    # Add production exchange for the activity `consumption`\n",
    "    consumption_all.new_exchange(\n",
    "        input=(consumption_all['database'], consumption_all['code']),\n",
    "        amount=1,\n",
    "        type='production',\n",
    "    ).save()\n",
    "    consumption_all['agg_option'] = option\n",
    "    consumption_all['n_households'] = n_households\n",
    "    consumption_all.save()\n",
    "    # Smth with codes\n",
    "    codes = [act['code'] for act in co]\n",
    "    unlinked_codes = []\n",
    "    for i in range(len(df)):\n",
    "        code = df.loc[i]['code']\n",
    "        uncertainty_dict = get_uncertainty(code)\n",
    "        if code in codes:\n",
    "            consumption_all.new_exchange(\n",
    "                input=(co.name, code),\n",
    "                amount=df.loc[i]['amount'],\n",
    "                type='technosphere',\n",
    "                **uncertainty_dict,\n",
    "                has_uncertainty=True,\n",
    "            ).save()\n",
    "        else:\n",
    "            unlinked_codes.append(code)\n",
    "\n",
    "    # Note that\n",
    "    # - the number of consumption exchanges is the same as the number of activities in the database,\n",
    "    # - but is a lot less than what Andi provided in his total demands. TODO not sure what this means anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.projects.set_current(\"GSA for archetypes\")\n",
    "co_name = \"swiss consumption 1.0\"\n",
    "co = bd.Database(co_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7109cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = co.random()\n",
    "list(a.exchanges())[1].as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ausgaben['a30'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb298d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lognorm.fit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099998dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aca02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(min(data), max(data), 10000)\n",
    "pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
    "       / (x * sigma * np.sqrt(2 * np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3657d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 200\n",
    "bins_ = np.linspace(min(data), max(data), num_bins, endpoint=True)\n",
    "freq, bins = np.histogram(data, bins=bins_)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=bins,\n",
    "        y=freq,\n",
    "        opacity=0.60,\n",
    "        showlegend=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcb7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57fc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261a052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b056b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c72e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07428a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.projects.set_current(\"GSA for archetypes\")\n",
    "co_name = \"swiss consumption 1.0\"\n",
    "\n",
    "co = bd.Database(co_name)\n",
    "year_habe = co.metadata['year_habe']\n",
    "dir_habe = co.metadata['dir_habe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342d5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f426bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
